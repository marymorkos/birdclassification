# -*- coding: utf-8 -*-
"""BirdClassification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AZJsGi2njx20IEg9tK94Oi-EAQp1lxeg

# Clean and PreProcess
"""

import pandas as pd

github_url = 'https://raw.githubusercontent.com/marymorkos/birdclassification/main/bird.csv'
bird_df = pd.read_csv(github_url)

bird_df.head()

##id: Sequential id
##huml: Length of Humerus (mm)
#humw: Diameter of Humerus (mm)
##ulnal: Length of Ulna (mm)
##ulnaw: Diameter of Ulna (mm)
##feml Length of Femur (mm)
##femw: Diameter of Femur (mm)
##tibl: Length of Tibiotarsus (mm)
##tibw: Diameter of Tibiotarsus (mm)
##tarl: Length of Tarsometatarsus (mm)

type_mapping = {
    'SW': 'Swimming Birds',
    'W': 'Wading Birds',
    'T': 'Terrestrial Birds',
    'R': 'Raptors',
    'P': 'Scansorial Birds',
    'SO': 'Singing Birds'
}

bird_df['type'] = bird_df['type'].map(type_mapping)

print(bird_df['type'].value_counts())

bird_df.head()

# Check for missing values
print("Missing values:\n", bird_df.isnull().sum())

import numpy as np

# Fill NaN values with the average of each numerical column
numerical_cols = bird_df.select_dtypes(include=np.number).columns
bird_df[numerical_cols] = bird_df[numerical_cols].fillna(bird_df[numerical_cols].mean())

# Confirm missing values have been filled
print("Missing values after filling with average:\n", bird_df.isnull().sum())

print("Duplicate rows:\n", bird_df.duplicated().sum())

bird_df.head()

bird_df = bird_df.drop(columns=['id'])

"""# Visualize what we have"""

import seaborn as sns
import matplotlib.pyplot as plt

# Create a boxplot to visualize the distribution of 'type' variable
plt.figure(figsize=(10, 6))
sns.boxplot(x='type', y='huml', data=bird_df)
plt.xlabel('Bird Type')
plt.ylabel('Huml')
plt.title('Distribution of Huml across Bird Types')
plt.xticks(rotation=45)  # Rotate x-axis labels for better readability
plt.grid(True)  # Add grid for better readability
plt.show()

plt.figure(figsize=(10, 6))
sns.countplot(x='type', data=bird_df)
plt.xlabel('Bird Type')
plt.ylabel('Count')
plt.title('Distribution of Bird Types')
plt.xticks(rotation=45)  # Rotate x-axis labels for better readability
plt.show()

"""# Prediction One: Random Forest Classifier"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix

# Split data into predictors (X) and target (y)
X = bird_df.drop(columns=['type'])
y = bird_df['type']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train the model
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

# Calculate accuracy score
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Create confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d', xticklabels=model.classes_, yticklabels=model.classes_)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

"""# Feature Importance"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Split data into predictors (X) and target (y)
X = bird_df.drop(columns=['type'])
y = bird_df['type']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train the model
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Calculate accuracy score
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

feature_importances = model.feature_importances_

# Create a DataFrame to store feature importances
feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})

# Sort the DataFrame by importance
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importance_df)
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.title('Feature Importances')
plt.show()

"""# Logistic Regression"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Splitting data into training and testing sets
X = bird_df[['huml', 'ulnal', 'ulnaw', 'feml', 'femw', 'tibl', 'tibw', 'tarl', 'tarw']]
y = bird_df['type']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.show()

report = classification_report(y_test, y_pred)

print("Classification Report:")
print(report)

plt.figure(figsize=(10, 6))
sns.countplot(x='type', data=bird_df)
plt.title('Distribution of Bird Types')
plt.xlabel('Bird Type')
plt.ylabel('Count')
plt.show()

"""# K-Fold CV"""

from sklearn.model_selection import cross_val_score, StratifiedKFold

model = RandomForestClassifier(random_state=42)

# Define the cross-validation strategy (Stratified k-fold with 5 folds)
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Perform cross-validation
cv_scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')

# Calculate mean cross-validation score
mean_cv_score = cv_scores.mean()
print("Mean Cross-Validation Score:", mean_cv_score)

import matplotlib.pyplot as plt
from sklearn.model_selection import cross_val_score
from sklearn.feature_selection import SelectFromModel
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

cv_scores = cross_val_score(LogisticRegression(), X, y, cv=5)

model = LogisticRegression()
model.fit(X_train, y_train)

plt.figure(figsize=(10, 6))
bars = plt.barh(X.columns, model.coef_[0])
plt.xlabel('Coefficient Magnitude')
plt.ylabel('Feature')
plt.title('Feature Importance from Logistic Regression Model')

# Add numbers to the bars
for bar in bars:
    width = bar.get_width()
    plt.text(width, bar.get_y() + bar.get_height()/2, f'{width:.2f}', ha='left', va='center')

plt.show()

threshold = 0.5
sfm = SelectFromModel(model, threshold=threshold)
sfm.fit(X_train, y_train)
selected_features = X.columns[sfm.get_support()]

param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}
grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)
grid_search.fit(X_train, y_train)

plt.figure(figsize=(8, 6))
plt.plot(param_grid['C'], grid_search.cv_results_['mean_test_score'], marker='o')
plt.xlabel('C')
plt.ylabel('Mean Cross-Validation Score')
plt.title('Parameter Tuning: Regularization Strength (C)')
plt.xscale('log')
plt.show()