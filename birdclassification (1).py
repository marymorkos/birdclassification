# -*- coding: utf-8 -*-
"""BirdClassification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AZJsGi2njx20IEg9tK94Oi-EAQp1lxeg

# Clean and PreProcess
"""

import pandas as pd

github_url = 'https://raw.githubusercontent.com/marymorkos/birdclassification/main/bird.csv'
bird_df = pd.read_csv(github_url)

bird_df.head()

##id: Sequential id
##huml: Length of Humerus (mm)
#humw: Diameter of Humerus (mm)
##ulnal: Length of Ulna (mm)
##ulnaw: Diameter of Ulna (mm)
##feml Length of Femur (mm)
##femw: Diameter of Femur (mm)
##tibl: Length of Tibiotarsus (mm)
##tibw: Diameter of Tibiotarsus (mm)
##tarl: Length of Tarsometatarsus (mm)

type_mapping = {
    'SW': 'Swimming Birds',
    'W': 'Wading Birds',
    'T': 'Terrestrial Birds',
    'R': 'Raptors',
    'P': 'Scansorial Birds',
    'SO': 'Singing Birds'
}

bird_df['type'] = bird_df['type'].map(type_mapping)

print(bird_df['type'].value_counts())

bird_df.head()

# Check for missing values
print("Missing values:\n", bird_df.isnull().sum())

import numpy as np

# Fill NaN values with the average of each numerical column
numerical_cols = bird_df.select_dtypes(include=np.number).columns
bird_df[numerical_cols] = bird_df[numerical_cols].fillna(bird_df[numerical_cols].mean())

# Confirm missing values have been filled
print("Missing values after filling with average:\n", bird_df.isnull().sum())

print("Duplicate rows:\n", bird_df.duplicated().sum())

bird_df.head()

bird_df = bird_df.drop(columns=['id'])

"""# Visualize what we have"""

import seaborn as sns
import matplotlib.pyplot as plt

# Create a boxplot to visualize the distribution of 'type' variable
plt.figure(figsize=(10, 6))
sns.boxplot(x='type', y='huml', data=bird_df)
plt.xlabel('Bird Type')
plt.ylabel('Huml')
plt.title('Distribution of Huml across Bird Types')
plt.xticks(rotation=45)  # Rotate x-axis labels for better readability
plt.grid(True)  # Add grid for better readability
plt.show()

plt.figure(figsize=(10, 6))
sns.countplot(x='type', data=bird_df)
plt.xlabel('Bird Type')
plt.ylabel('Count')
plt.title('Distribution of Bird Types')
plt.xticks(rotation=45)  # Rotate x-axis labels for better readability
plt.show()

"""# Prediction One: Random Forest Classifier"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix

# Split data into predictors (X) and target (y)
X = bird_df.drop(columns=['type'])
y = bird_df['type']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train the model
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

# Calculate accuracy score
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Create confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d', xticklabels=model.classes_, yticklabels=model.classes_)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

"""# Feature Importance"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Split data into predictors (X) and target (y)
X = bird_df.drop(columns=['type'])
y = bird_df['type']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train the model
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Calculate accuracy score
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

feature_importances = model.feature_importances_

# Create a DataFrame to store feature importances
feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})

# Sort the DataFrame by importance
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importance_df)
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.title('Feature Importances')
plt.show()

"""# Logistic Regression"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Splitting data into training and testing sets
X = bird_df[['huml', 'ulnal', 'ulnaw', 'feml', 'femw', 'tibl', 'tibw', 'tarl', 'tarw']]
y = bird_df['type']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.show()

report = classification_report(y_test, y_pred)

print("Classification Report:")
print(report)
##bird species is encoded
##Swimming Birds 0
##Wading Birds 1
##Terrestrial Birds 2
##Raptors 3
##Scansorial Birds 4
##Singing Birds 5

"""# Preditction Two: Linear Regression"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8, 6))
sns.histplot(bird_df['huml'], bins=20, kde=True)
plt.title('Distribution of Humerus Length (huml)')
plt.xlabel('Humerus Length')
plt.ylabel('Frequency')
plt.show()

##create yo model
predictors = ['humw', 'ulnal', 'ulnaw', 'feml', 'femw', 'tibl', 'tibw', 'tarl', 'tarw']
target = 'huml'

##yess split it up
X_train, X_test, y_train, y_test = train_test_split(bird_df[predictors], bird_df[target], test_size=0.2, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print("Mean Squared Error (MSE):", mse)
print("R-squared (R^2) Score:", r2)

coefficients = pd.Series(model.coef_, index=predictors)
print("\nCoefficients:")
print(coefficients)

plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred)
plt.xlabel("Actual Humerus Length")
plt.ylabel("Predicted Humerus Length")
plt.title("Actual vs. Predicted Humerus Length")
plt.show()

"""# Tuning and Validation"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import cross_val_score, KFold, GridSearchCV
from sklearn.feature_selection import RFE
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder

github_url = 'https://raw.githubusercontent.com/marymorkos/birdclassification/main/bird.csv'
bird_df = pd.read_csv(github_url)

numerical_cols = bird_df.select_dtypes(include=np.number).columns
bird_df[numerical_cols] = bird_df[numerical_cols].fillna(bird_df[numerical_cols].mean())

print("Missing values after filling with average:\n", bird_df.isnull().sum())

label_encoder = LabelEncoder()
bird_df['type'] = label_encoder.fit_transform(bird_df['type'])

# Separate features and target variable
X = bird_df.drop(columns=['id', 'type'])
y = bird_df['type']

model = RandomForestClassifier(random_state=42)
cv = KFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = cross_val_score(model, X, y, cv=cv)
print("Cross-validation scores:", cv_scores)

rfe = RFE(estimator=model, n_features_to_select=5, step=1)
rfe.fit(X, y)
selected_features = np.array(X.columns)[rfe.support_]
print("Selected features:", selected_features)

param_grid = {
    'n_estimators': [50, 100, 150],
    'max_depth': [None, 5, 10]
}

grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv)
grid_search.fit(X, y)

means = grid_search.cv_results_['mean_test_score']
params = grid_search.cv_results_['params']

plt.figure(figsize=(10, 6))
for mean, param in zip(means, params):
    plt.scatter(param['n_estimators'], param['max_depth'], c=mean, cmap='viridis', s=100, edgecolors='k')

plt.colorbar(label='Mean Test Score')
plt.xlabel('n_estimators')
plt.ylabel('max_depth')
plt.title('Grid Search Results')
plt.show()

n_estimators_values = sorted(list(set(param['n_estimators'] for param in params)))
max_depth_values = sorted(list(set(param['max_depth'] for param in params if param['max_depth'] is not None))) + ['None']
mean_scores_matrix = np.array(means).reshape(len(max_depth_values), len(n_estimators_values))

# Create heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(mean_scores_matrix, annot=True, cmap='viridis', xticklabels=n_estimators_values, yticklabels=max_depth_values)
plt.xlabel('n_estimators')
plt.ylabel('max_depth')
plt.title('Grid Search Results - Mean Test Score')
plt.show()